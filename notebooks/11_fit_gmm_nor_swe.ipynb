{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1751130193129,
     "user": {
      "displayName": "Memmi Fares",
      "userId": "15855632919481292755"
     },
     "user_tz": -60
    },
    "id": "WM9nMGmhfSzs",
    "outputId": "5d5c0a08-cf2d-4efd-dbc9-315cd67595f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/content/utils.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import itertools\n",
    "import importlib\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from shapely.geometry import shape\n",
    "import nimfa\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up plotting style (optional, but professional)\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHY-6Vs3guQi"
   },
   "source": [
    "# Define Folder Path & Sensor IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BI7ZGvzSfS-_"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define the base data folder\n",
    "FolderPath = Path(\".../Data/NorSwe/\")  # Change to your path\n",
    "\n",
    "Sensors = [\n",
    "    \"01777V885181\", \"77275V885276\", \"35829V885266\", \"99923V578123\",\n",
    "    \"50089V578151\", \"84237V578097\", \"76778V704564\", \"69140V704643\",\n",
    "    \"57929V705247\", \"52209V971422\", \"00737V704646\", \"94864V704707\",\n",
    "    \"94299V704696\", \"05732V971567\", \"21405V2607269\", \"09269V971425\",\n",
    "    \"02535V971411\", \"04904V971774\", \"35229V971507\"\n",
    "]\n",
    "\n",
    "fit_dates = {\n",
    "    \"01777V885181\": [datetime.date(2017, 1, 1),datetime.date(2020,3,12)],\n",
    "    \"77275V885276\": [datetime.date(2017, 1, 1),datetime.date(2020,3,12)],\n",
    "    \"35829V885266\": [datetime.date(2018, 1, 15),datetime.date(2020,3,12)],\n",
    "    \"99923V578123\": [datetime.date(2017, 1, 1),datetime.date(2020,3,12)],\n",
    "    \"50089V578151\": [datetime.date(2019, 1, 1),datetime.date(2019,12,31)],\n",
    "    \"84237V578097\": [datetime.date(2017, 1, 1),datetime.date(2020,3,12)],\n",
    "    \"76778V704564\": [datetime.date(2017, 1, 1),datetime.date(2020,3,12)],\n",
    "    \"69140V704643\": [datetime.date(2017, 1, 1),datetime.date(2020,3,12)],\n",
    "    \"57929V705247\": [datetime.date(2017, 1, 1),datetime.date(2018,5,30)],\n",
    "    \"52209V971422\": [datetime.date(2018, 1, 1),datetime.date(2020,3,12)],\n",
    "    \"00737V704646\": [datetime.date(2017, 1, 1),datetime.date(2020,3,12)],\n",
    "    \"94864V704707\": [datetime.date(2017, 1, 1),datetime.date(2020,3,12)],\n",
    "    \"94299V704696\": [datetime.date(2017, 1, 1),datetime.date(2020,3,12)],\n",
    "    \"05732V971567\": [datetime.date(2017, 10, 1),datetime.date(2020,3,12)],\n",
    "    \"21405V2607269\": [datetime.date(2019, 3, 1),datetime.date(2020,3,12)],\n",
    "    \"09269V971425\": [datetime.date(2018, 3, 1),datetime.date(2020,3,12)],\n",
    "    \"02535V971411\": [datetime.date(2019, 1, 1),datetime.date(2020,3,12)],\n",
    "    \"04904V971774\": [datetime.date(2017, 1, 1),datetime.date(2020,3,12)],\n",
    "    \"35229V971507\": [datetime.date(2017, 1, 1),datetime.date(2020,3,12)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "288QIwdZg6JM"
   },
   "source": [
    "# Read Sensor CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItySvezqg65L"
   },
   "outputs": [],
   "source": [
    "sensor_dict = {}\n",
    "all_data = []\n",
    "for s in Sensors:\n",
    "    df = pd.read_csv(FolderPath + s + '_by_length_hour.csv', sep=',',\n",
    "                     usecols=['sensor_id', 'from_date', 'to_date', 'from_hour', 'to_hour',\n",
    "                              'sensor_dir', 'short_vehicles', 'long_vehicles', 'unknown_length'],\n",
    "                     parse_dates=['from_date', 'to_date'])\n",
    "    sensor_dict[s] = {\n",
    "        'Start': df['from_date'].min(),\n",
    "        'End': df['to_date'].max(),\n",
    "        'Directions': df['sensor_dir'].unique()\n",
    "    }\n",
    "    all_data.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qoZL9I3hAMy"
   },
   "source": [
    "# Standardize Direction Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8zEjGsmhCQ5"
   },
   "outputs": [],
   "source": [
    "to_norway = [\n",
    "    'Trældal x Ev6', 'Hestbrinken', 'Mo i Rana', 'Trofors', 'Hattfjelldalen',\n",
    "    'Gjersvika', 'Sandvika', 'Nordli', 'Verdalsøra', 'Meråker', 'Drevsjø',\n",
    "    'ØSTBY', 'X/RV 25', 'NYBERGSUND', 'Holtet', 'Røgden', 'ØYERMOEN XF202',\n",
    "    'KONGSVINGER', 'BEKKENGA', 'Oslo', 'Halden', 'HALDEN', 'OSLO'\n",
    "]\n",
    "\n",
    "for df in all_data:\n",
    "    df['sensor_dir'] = np.where(df['sensor_dir'].isin(to_norway), 'NOR', 'SWE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80rwA3-9iiUp"
   },
   "outputs": [],
   "source": [
    "def agg_APIdata_NORSWE(data,WhichVehicles,min_date = datetime.datetime(2017, 1, 1)  , max_date = datetime.datetime(2023, 5, 22)):\n",
    "\n",
    "#WhichVehicles can be 'Small', 'Heavy', 'Total' or 'Both'\n",
    "\n",
    "    # What vehicle lengths do we want\n",
    "    if WhichVehicles == 'Total':\n",
    "        data['total_vehicles'] = data['short_vehicles'] + data['long_vehicles'] + data['unknown_length']\n",
    "    elif WhichVehicles == 'Small':\n",
    "        data = data.rename(columns={'short_vehicles':'total_vehicles'})\n",
    "    elif WhichVehicles == 'Heavy':\n",
    "        data = data.rename(columns={'long_vehicles': 'total_vehicles'})\n",
    "\n",
    "    # Create sensor direction and origin columns\n",
    "    data = data.rename(columns = {'sensor_dir': 'dest_country'})\n",
    "    data['origin_country'] = np.where(data['dest_country'] == 'NOR', 'SWE','NOR')\n",
    "\n",
    "    data['sensor_id'] = data['sensor_id'].astype(str)\n",
    "\n",
    "    data['sensor_origin'] = data[['sensor_id', 'origin_country']].agg(', '.join, axis=1)\n",
    "    data['sensor_destination'] = data[['sensor_id', 'dest_country']].agg(', '.join, axis=1)\n",
    "\n",
    "    ## Add some temporal informaiton.\n",
    "\n",
    "    data = data.drop(['to_date'], axis = 1).rename(columns = {'from_date':'date'})\n",
    "\n",
    "    data['minute'] = datetime.timedelta(minutes = 0)\n",
    "\n",
    "\n",
    "    data = data[~(data['from_hour'] == data['to_hour'])].rename(columns = {'from_hour':'hour'})\n",
    "\n",
    "    data['hour'] = pd.to_timedelta(data['hour'].apply(lambda x: int(x[:2])), unit='h')\n",
    "\n",
    "    data['date'] = data['date'] + data['hour'] + data['minute']\n",
    "    data = data[(data.date > min_date) & (data.date < max_date)].copy()\n",
    "\n",
    "    if WhichVehicles == 'Both':\n",
    "        data = data[['sensor_origin','sensor_destination','date','small_vehicles','long_vehicles','unknown_length']].copy()\n",
    "\n",
    "    else:\n",
    "        data = data[['sensor_origin', 'sensor_destination', 'date', 'total_vehicles']].copy().reset_index()\n",
    "        rm_idx = np.where(np.isnan(data.total_vehicles))\n",
    "        data = data.drop(index = rm_idx[0])\n",
    "        data['total_vehicles'] = data['total_vehicles'].apply(lambda x: int(x))\n",
    "\n",
    "        f = lambda x: x.reindex(pd.date_range(min_date,\n",
    "                                                max_date,\n",
    "                                                name='date',\n",
    "                                                freq='1h'), fill_value=0)\n",
    "\n",
    "\n",
    "        data = (data.set_index('date')\n",
    "                    .groupby([\"sensor_origin\", \"sensor_destination\"])[\"total_vehicles\"]\n",
    "                    .apply(f)\n",
    "                    .reset_index())\n",
    "        data = data.pivot_table(index=[\"sensor_origin\",\"sensor_destination\"], columns=[\"date\"],values=[\"total_vehicles\"] ).droplevel(level = 0,axis = 1 )\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsUf9k_khFQs"
   },
   "source": [
    "# Aggregate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJG4sfhhhHnU"
   },
   "outputs": [],
   "source": [
    "agg_data = []\n",
    "for df in all_data:\n",
    "    d = agg_APIdata_NORSWE(df, 'Small',\n",
    "        min_date=datetime.datetime(2017, 1, 1),\n",
    "        max_date=datetime.datetime(2023, 12, 31))\n",
    "    agg_data.append(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-wy3WMVhHuL"
   },
   "source": [
    "# Fit Bayesian GMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4835291,
     "status": "ok",
     "timestamp": 1751136002374,
     "user": {
      "displayName": "Memmi Fares",
      "userId": "15855632919481292755"
     },
     "user_tz": -60
    },
    "id": "6oxSkK-4hHzJ",
    "outputId": "56d29512-457f-40db-ceda-1073d5b88ef9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n",
      "/content/drive/MyDrive/STAGE ING-2025/Data/utils.py:122: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  models = data[c].reset_index(\"weekday\").groupby(\"weekday\").agg(lambda x : fit_model(x,hourly_data, nSamp, N = N, hourminute = True,seed = seed, FitMethod = FitMethod))\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "data = []\n",
    "for df in agg_data:\n",
    "    sensor_id = df.index[0][0].split(',')[0]\n",
    "    d1, d2 = fit_dates[sensor_id]\n",
    "    mod, dat = utils.fit_period(df, d1=d1, d2=d2, hourly=True,\n",
    "                                 nSamp=10000, Normalize=False, N=10,\n",
    "                                 seed=2024, FitMethod='Bayesian')\n",
    "    models.append(mod)\n",
    "    data.append(dat)\n",
    "\n",
    "# Combine and Save\n",
    "models = pd.concat(models, axis=1)\n",
    "data = pd.concat(data, axis=0)\n",
    "agg_data = pd.concat(agg_data, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the fitted models and processed data to disk for later use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\".../Data/NorSwe_GMM\")  # cleaner & portable\n",
    "MODELS_FILE = BASE_DIR / \"models_nor.pkl\"\n",
    "DATA_FILE = BASE_DIR / \"data_nor.pkl\"\n",
    "AGG_DATA_FILE = BASE_DIR / \"agg_data_nor.pkl\"\n",
    "\n",
    "# Save\n",
    "models.to_pickle(MODELS_FILE)\n",
    "data.to_pickle(DATA_FILE)\n",
    "agg_data.to_pickle(AGG_DATA_FILE)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOS2LvnM5KxzobV8Nz8rB7K",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
